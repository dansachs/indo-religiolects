{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Upload Model to Hugging Face Hub\n",
        "\n",
        "This notebook uploads your trained model to Hugging Face Hub.\n",
        "\n",
        "## Setup\n",
        "\n",
        "1. **Get Hugging Face Token**:\n",
        "   - Go to https://huggingface.co/settings/tokens\n",
        "   - Create a new token with **\"write\"** permissions\n",
        "   - Copy the token\n",
        "\n",
        "2. **Update Configuration**:\n",
        "   - Update `MODEL_PATH` to point to your trained model\n",
        "   - Update `REPO_ID` if you want a different repository name\n",
        "\n",
        "3. **Run all cells**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install huggingface_hub -U -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "**Update these values:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# CONFIGURATION\n",
        "# ==========================================\n",
        "\n",
        "# Path to your trained model in Google Drive\n",
        "# Update this to your actual model path\n",
        "MODEL_PATH = \"/content/drive/MyDrive/Indo_Religiolect_V2/model_final\"  # IndoBERT\n",
        "# MODEL_PATH = \"/content/drive/MyDrive/Indo_Religiolect_V2/model_sahabat_ai\"  # Sahabat-AI\n",
        "\n",
        "# Hugging Face repository ID (your username/repo-name)\n",
        "REPO_ID = \"dansachs/indo-religiolect-bert\"\n",
        "\n",
        "# Your Hugging Face token (get from https://huggingface.co/settings/tokens)\n",
        "# Option 1: Paste token here (will be visible in notebook)\n",
        "HF_TOKEN = \"\"  # Paste your token here\n",
        "\n",
        "# Option 2: Use environment variable (more secure)\n",
        "# Set this in Colab: Runtime ‚Üí Change runtime type ‚Üí Environment variables\n",
        "# Or use: import os; os.environ[\"HF_TOKEN\"] = \"your_token_here\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from huggingface_hub import HfApi, login\n",
        "from huggingface_hub.utils import HfHubHTTPError\n",
        "import json\n",
        "\n",
        "# Set token if provided\n",
        "if HF_TOKEN:\n",
        "    os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
        "\n",
        "# Check model path\n",
        "model_path = Path(MODEL_PATH)\n",
        "if not model_path.exists():\n",
        "    raise FileNotFoundError(f\"‚ùå Model path does not exist: {MODEL_PATH}\")\n",
        "\n",
        "print(f\"üìÇ Model path: {MODEL_PATH}\")\n",
        "print(f\"üì¶ Repository: {REPO_ID}\")\n",
        "print(f\"\\n‚úÖ Configuration ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check model files\n",
        "print(\"üîç Checking model files...\")\n",
        "\n",
        "required_files = [\"config.json\"]\n",
        "model_file = None\n",
        "\n",
        "if (model_path / \"pytorch_model.bin\").exists():\n",
        "    model_file = \"pytorch_model.bin\"\n",
        "elif (model_path / \"model.safetensors\").exists():\n",
        "    model_file = \"model.safetensors\"\n",
        "else:\n",
        "    raise FileNotFoundError(\"‚ùå Model file not found (pytorch_model.bin or model.safetensors)\")\n",
        "\n",
        "print(f\"   ‚úÖ Found: config.json\")\n",
        "print(f\"   ‚úÖ Found: {model_file}\")\n",
        "\n",
        "# Check for tokenizer\n",
        "if (model_path / \"tokenizer_config.json\").exists():\n",
        "    print(f\"   ‚úÖ Found: tokenizer files\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è  Tokenizer files not found (will upload model only)\")\n",
        "\n",
        "# Check for label map\n",
        "if (model_path / \"label_map.json\").exists():\n",
        "    print(f\"   ‚úÖ Found: label_map.json\")\n",
        "\n",
        "print(\"\\n‚úÖ All required files found!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Login to Hugging Face\n",
        "print(\"üîê Logging in to Hugging Face...\")\n",
        "\n",
        "if os.getenv(\"HF_TOKEN\"):\n",
        "    print(\"   ‚úÖ Using token from environment\")\n",
        "    login(token=os.getenv(\"HF_TOKEN\"), add_to_git_credential=True)\n",
        "else:\n",
        "    print(\"   üí° You'll be prompted to enter your token.\")\n",
        "    print(\"   üí° Get one at: https://huggingface.co/settings/tokens\")\n",
        "    login()\n",
        "\n",
        "print(\"‚úÖ Logged in successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize API and check repository\n",
        "api = HfApi()\n",
        "\n",
        "print(f\"üì¶ Checking repository: {REPO_ID}\")\n",
        "try:\n",
        "    api.repo_info(REPO_ID, repo_type=\"model\")\n",
        "    print(f\"   ‚ö†Ô∏è  Repository already exists. Will update it.\")\n",
        "    overwrite = True\n",
        "except HfHubHTTPError as e:\n",
        "    if e.status_code == 404:\n",
        "        print(f\"   ‚úÖ Repository doesn't exist. Will create it.\")\n",
        "        overwrite = False\n",
        "    else:\n",
        "        raise\n",
        "\n",
        "print(\"\\n‚úÖ Ready to upload!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload model files\n",
        "print(f\"üì§ Uploading model files...\")\n",
        "print(f\"   From: {MODEL_PATH}\")\n",
        "print(f\"   To: {REPO_ID}\")\n",
        "print(f\"   This may take a few minutes...\\n\")\n",
        "\n",
        "try:\n",
        "    api.upload_folder(\n",
        "        folder_path=str(model_path),\n",
        "        repo_id=REPO_ID,\n",
        "        repo_type=\"model\",\n",
        "        ignore_patterns=[\"*.log\", \"*.png\", \"__pycache__\", \"*.pyc\"],  # Skip logs and cache\n",
        "    )\n",
        "    print(\"\\n‚úÖ Model files uploaded successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Error uploading files: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and upload model card (README.md)\n",
        "print(\"üìù Creating model card...\")\n",
        "\n",
        "# Load training info if available\n",
        "training_info = {}\n",
        "info_file = model_path / \"training_info.json\"\n",
        "if info_file.exists():\n",
        "    with open(info_file, 'r') as f:\n",
        "        training_info = json.load(f)\n",
        "\n",
        "# Load label map\n",
        "label_map = {}\n",
        "label_file = model_path / \"label_map.json\"\n",
        "if label_file.exists():\n",
        "    with open(label_file, 'r') as f:\n",
        "        label_map = json.load(f)\n",
        "\n",
        "# Create model card\n",
        "model_name = training_info.get(\"model_name\", \"indolem/indobert-base-uncased\")\n",
        "num_epochs = training_info.get(\"num_epochs\", \"N/A\")\n",
        "train_samples = training_info.get(\"train_samples\", \"N/A\")\n",
        "\n",
        "# Format train_samples\n",
        "if isinstance(train_samples, int):\n",
        "    train_samples_str = f\"{train_samples:,}\"\n",
        "else:\n",
        "    train_samples_str = str(train_samples)\n",
        "\n",
        "# Format label_map\n",
        "if label_map:\n",
        "    labels_str = str(label_map)\n",
        "else:\n",
        "    labels_str = \"Islam (0), Catholic (1), Protestant (2)\"\n",
        "\n",
        "model_card = f\"\"\"---\n",
        "license: apache-2.0\n",
        "base_model: {model_name}\n",
        "tags:\n",
        "  - indonesian\n",
        "  - classification\n",
        "  - religiolect\n",
        "  - bert\n",
        "  - text-classification\n",
        "---\n",
        "\n",
        "# Indo-Religiolect-BERT\n",
        "\n",
        "A fine-tuned Indonesian BERT model for classifying religious texts into:\n",
        "- **Islam** (Muslim)\n",
        "- **Catholic**\n",
        "- **Protestant**\n",
        "\n",
        "## Model Details\n",
        "\n",
        "- **Base Model**: `{model_name}`\n",
        "- **Task**: Sequence Classification\n",
        "- **Language**: Indonesian\n",
        "- **Labels**: {labels_str}\n",
        "- **Training Epochs**: {num_epochs}\n",
        "- **Training Samples**: {train_samples_str}\n",
        "\n",
        "## Training Data\n",
        "\n",
        "Trained on ~2 million Indonesian religious text sentences collected from:\n",
        "- Catholic websites\n",
        "- Islamic websites  \n",
        "- Protestant websites\n",
        "\n",
        "## Usage\n",
        "\n",
        "```python\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Load model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"{REPO_ID}\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"{REPO_ID}\")\n",
        "\n",
        "# Predict\n",
        "text = \"Allah adalah Tuhan yang Maha Esa\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
        "outputs = model(**inputs)\n",
        "prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
        "\n",
        "label_map = {{0: 'Islam', 1: 'Catholic', 2: 'Protestant'}}\n",
        "print(f\"Prediction: {{label_map[prediction]}}\")\n",
        "```\n",
        "\n",
        "## Performance\n",
        "\n",
        "Model performance metrics are available in the training logs.\n",
        "\n",
        "## Citation\n",
        "\n",
        "If you use this model, please cite:\n",
        "```\n",
        "@misc{{indo-religiolect-bert,\n",
        "  author = {{Dan Sachs}},\n",
        "  title = {{Indo-Religiolect-BERT: Indonesian Religious Text Classifier}},\n",
        "  year = {{2024}},\n",
        "  publisher = {{Hugging Face}},\n",
        "  howpublished = {{\\\\\\\\url{{https://huggingface.co/{REPO_ID}}}}}\n",
        "}}\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "# Upload model card\n",
        "print(\"üì§ Uploading model card (README.md)...\")\n",
        "try:\n",
        "    api.upload_file(\n",
        "        path_or_fileobj=model_card.encode('utf-8'),\n",
        "        path_in_repo=\"README.md\",\n",
        "        repo_id=REPO_ID,\n",
        "        repo_type=\"model\",\n",
        "    )\n",
        "    print(\"‚úÖ Model card uploaded!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Could not upload model card: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ UPLOAD COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nüåê View your model at:\")\n",
        "print(f\"   https://huggingface.co/{REPO_ID}\")\n",
        "\n",
        "if training_info:\n",
        "    print(f\"\\nüìä Training Information:\")\n",
        "    for key, value in training_info.items():\n",
        "        if key != \"label_map\":  # Skip label_map in summary\n",
        "            print(f\"   {key}: {value}\")\n",
        "\n",
        "print(f\"\\nüí° To use this model:\")\n",
        "print(f\"   from transformers import AutoTokenizer, AutoModelForSequenceClassification\")\n",
        "print(f\"   tokenizer = AutoTokenizer.from_pretrained('{REPO_ID}')\")\n",
        "print(f\"   model = AutoModelForSequenceClassification.from_pretrained('{REPO_ID}')\")\n",
        "\n",
        "print(f\"\\n‚ú® Your model is now publicly available on Hugging Face!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
